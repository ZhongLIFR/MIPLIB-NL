{
  "abstract_problem": "A large-scale high-performance computing center is deploying a new network topology consisting of {n} distinct server clusters, indexed sequentially from 1 to {n}. Each cluster contains exactly 12 processing units, labeled 0 through 11. To optimize thermal management, processing units with even indices utilize liquid cooling while those with odd indices rely on air cooling, resulting in a 15% difference in maintenance protocols, though they function identically in the network. The network topology is defined as follows: Inside every cluster, a primary data loop is formed by connecting units 0, 1, 2, 3, 4, 5, and 6 in that specific order, closing the loop by connecting 6 back to 0. A secondary security loop is established by connecting units 7, 9, 11, 8, and 10 in that sequence, with unit 10 connecting back to unit 7. High-speed internal bridges are then installed to link the two loops: unit 0 connects to 7, unit 2 to 8, unit 5 to 10, and unit 6 to 11. In standard clusters (indices 2 through {n}), an additional bridge connects unit 3 to unit 9. However, due to a distinct chipset architecture in the prototype cluster (cluster index 1), unit 3 is not connected to unit 9; instead, the bridge connects unit 4 to unit 9. For inter-cluster communication, a low-latency trunk line connects unit 4 of each cluster k (where k > 1) to unit 1 of the preceding cluster k-1. The fiber optic cables used for intra-cluster connections cost $50 per meter, whereas inter-cluster trunk lines cost $200 per meter due to shielding requirements. The system architect needs to assign communication channels (wavelengths) to every connection such that no two connections terminating at the same processing unit share the same channel. What is the minimum number of distinct channels required to maximize spectrum efficiency?",
  "parameters": {
    "n": 32
  },
  "files": {},
  "optimal_value": 4
}
